# WorkHub AI Sales System

Sistema completo de vendas com IA para espaÃ§os de coworking, implementando agentes inteligentes (Vendas, Analista e Admin) usando **FastAPI + LangChain + OpenAI**.

## âš¡ InÃ­cio RÃ¡pido

```bash
# 1. Clone o repositÃ³rio
git clone <repository-url>
cd teste_bluelephant-morphia

# 2. Configure o .env com sua chave OpenAI
cp env.example .env
# Edite .env e adicione: OPENAI_API_KEY=sk-your-key-here

# 3. Execute o Docker
docker-compose up --build

# 4. Aguarde o seed automÃ¡tico (acontece no startup)
# 5. Acesse http://localhost:8000/chat
```

**âš ï¸ Requisitos:** Docker, Docker Compose e conta OpenAI com API Key.

## ğŸ“‹ Sobre o Projeto

Este projeto demonstra uma arquitetura robusta de agentes de IA com **Function Calling/Tools** para interaÃ§Ã£o estruturada com banco de dados PostgreSQL.

### Agentes DisponÃ­veis

- **Sales Agent**: Conversar com clientes, recomendar planos, superar objeÃ§Ãµes e fechar vendas
- **Analyst Agent**: Analisar conversas, identificar padrÃµes, calcular mÃ©tricas e sugerir melhorias
- **Admin Agent**: Acesso administrativo para anÃ¡lise de vendas, gestÃ£o de leads e mÃ©tricas detalhadas

### DomÃ­nio de NegÃ³cio: WorkHub Coworking

WorkHub Ã© um espaÃ§o de coworking fictÃ­cio com 3 planos:
- **Day Pass** (R$ 49/dia): Acesso por 1 dia
- **Flex** (R$ 497/mÃªs): 10 dias de acesso por mÃªs
- **Dedicado** (R$ 897/mÃªs): Acesso ilimitado 24/7

## ğŸ—ï¸ Arquitetura

### Stack TecnolÃ³gica

- **Backend**: Python 3.11+, FastAPI
- **IA/LLM**: LangChain, OpenAI GPT-4 (Google Gemini como alternativa)
- **Banco de Dados**: PostgreSQL (Async)
- **ORM**: SQLAlchemy 2.0 (Async)
- **Migrations**: Alembic
- **Testes**: Pytest, Pytest-Asyncio
- **ContainerizaÃ§Ã£o**: Docker, Docker Compose

### Diagrama de Arquitetura

```mermaid
graph TB
    subgraph frontend["Frontend"]
        UI["Interface Web"]
    end
    
    subgraph apiLayer["API Layer"]
        API["FastAPI Endpoints"]
        ChatAPI["/api/v1/chat"]
        AnalyticsAPI["/api/v1/analytics"]
    end
    
    subgraph serviceLayer["Service Layer"]
        ChatService["Chat Service"]
        AnalystService["Analyst Service"]
        PromptService["Prompt Service"]
    end
    
    subgraph agentLayer["Agent Layer"]
        SalesAgent["Sales Agent"]
        AnalystAgent["Analyst Agent"]
        AdminAgent["Admin Agent"]
    end
    
    subgraph toolsLayer["Tools Layer"]
        UserTools["User Tools"]
        ConversationTools["Conversation Tools"]
        LeadTools["Lead Tools"]
        AnalyticsTools["Analytics Tools"]
        PlanTools["Plan Tools"]
    end
    
    subgraph llmProvider["LLM Provider"]
        OpenAI["OpenAI GPT-4 (Principal)"]
        Gemini["Google Gemini (Alternativo)"]
    end
    
    subgraph database["Database"]
        PostgreSQL[("PostgreSQL")]
    end
    
    UI --> API
    API --> ChatAPI
    API --> AnalyticsAPI
    ChatAPI --> ChatService
    AnalyticsAPI --> AnalystService
    ChatService --> SalesAgent
    ChatService --> AdminAgent
    AnalystService --> AnalystAgent
    SalesAgent --> UserTools
    SalesAgent --> ConversationTools
    SalesAgent --> LeadTools
    SalesAgent --> PlanTools
    AdminAgent --> AnalyticsTools
    AdminAgent --> ConversationTools
    AnalystAgent --> AnalyticsTools
    SalesAgent --> OpenAI
    SalesAgent --> Gemini
    AdminAgent --> OpenAI
    AdminAgent --> Gemini
    AnalystAgent --> OpenAI
    AnalystAgent --> Gemini
    UserTools --> PostgreSQL
    ConversationTools --> PostgreSQL
    LeadTools --> PostgreSQL
    AnalyticsTools --> PostgreSQL
    PlanTools --> PostgreSQL
```

### Fluxo de Conversa

```mermaid
sequenceDiagram
    participant User
    participant API
    participant ChatService
    participant SalesAgent
    participant LLM
    participant Tools
    participant DB
    
    User->>API: POST /api/v1/chat
    API->>ChatService: process_message()
    ChatService->>ChatService: get_or_create_user()
    ChatService->>ChatService: get_or_create_conversation()
    ChatService->>SalesAgent: invoke()
    SalesAgent->>LLM: Chat with tools
    LLM->>Tools: Call tool (e.g., get_available_plans)
    Tools->>DB: Query database
    DB-->>Tools: Return data
    Tools-->>LLM: Tool result
    LLM-->>SalesAgent: Response with tool calls
    SalesAgent->>ChatService: Return response
    ChatService->>DB: Save message
    ChatService-->>API: Return response
    API-->>User: JSON response
```

### Funil de Vendas

```mermaid
graph LR
    A["Awareness"] -->|"Interesse"| B["Interest"]
    B -->|"ConsideraÃ§Ã£o"| C["Consideration"]
    C -->|"NegociaÃ§Ã£o"| D["Negotiation"]
    D -->|"Fechado"| E["Closed Won"]
    D -->|"Perdido"| F["Closed Lost"]
    A -->|"Sem interesse"| F
```

## ğŸš€ Quick Start

### âš ï¸ PrÃ©-requisitos

Antes de comeÃ§ar, certifique-se de ter:

1. **Docker e Docker Compose instalados**
   - Docker Desktop: https://www.docker.com/products/docker-desktop
   - Ou Docker Engine + Docker Compose
   - Verifique a instalaÃ§Ã£o: `docker --version` e `docker-compose --version`

2. **Conta OpenAI com API Key**
   - Este projeto foi desenvolvido para usar **OpenAI** como provider principal
   - Crie uma conta em: https://platform.openai.com
   - Obtenha sua API Key em: https://platform.openai.com/api-keys
   - VocÃª precisarÃ¡ de crÃ©ditos na conta OpenAI para usar a API

### 1. Clone o RepositÃ³rio

```bash
git clone <repository-url>
cd teste_bluelephant-morphia
```

### 2. Configure o Arquivo `.env`

Crie um arquivo `.env` na raiz do projeto. VocÃª pode usar o arquivo de exemplo:

```bash
# Linux/Mac
cp env.example .env

# Windows (PowerShell)
Copy-Item env.example .env
```

Ou crie manualmente o arquivo `.env` com o conteÃºdo abaixo.

Edite o arquivo `.env` e adicione sua chave da OpenAI:

```env
# OpenAI (REQUERIDO - Provider principal do projeto)
OPENAI_API_KEY=sk-your-openai-api-key-here
OPENAI_MODEL=gpt-4o-mini

# Provider LLM (padrÃ£o: openai)
LLM_PROVIDER=openai

# Database (jÃ¡ configurado para Docker - ALTERE EM PRODUÃ‡ÃƒO)
DATABASE_URL=postgresql+asyncpg://workhub:workhub123@db:5432/workhub_db

# Ambiente
APP_ENV=development
LOG_LEVEL=INFO
```

**âš ï¸ IMPORTANTE:**
- O projeto foi desenvolvido para usar **OpenAI** como provider principal
- VocÃª precisa de uma API Key vÃ¡lida da OpenAI
- Obtenha sua chave em: https://platform.openai.com/api-keys
- O modelo padrÃ£o Ã© `gpt-4o-mini` (mais econÃ´mico)
- VocÃª pode usar `gpt-4o` ou `gpt-3.5-turbo` se preferir

**Exemplo de `.env` completo:**
```env
OPENAI_API_KEY=sk-your-openai-api-key-here
OPENAI_MODEL=gpt-4o-mini
LLM_PROVIDER=openai
DATABASE_URL=postgresql+asyncpg://workhub:workhub123@db:5432/workhub_db
APP_ENV=development
LOG_LEVEL=INFO
AUTO_SEED=true
```

**âš ï¸ SEGURANÃ‡A:** 
- As credenciais do banco de dados (`workhub123`) sÃ£o apenas para desenvolvimento local
- **Em produÃ§Ã£o**, altere todas as senhas e use variÃ¡veis de ambiente seguras
- Nunca commite arquivos `.env` com chaves reais no repositÃ³rio

### 3. Execute o Docker Compose

Inicie todos os serviÃ§os (banco de dados + aplicaÃ§Ã£o):

```bash
docker-compose up --build
```

**O que acontece:**
- âœ… Baixa as imagens necessÃ¡rias (PostgreSQL, Python)
- âœ… Cria e inicia o container do PostgreSQL na porta 5432
- âœ… Cria e inicia o container da aplicaÃ§Ã£o FastAPI
- âœ… Executa as migrations do banco automaticamente
- âœ… Inicia o servidor FastAPI na porta 8000

**âš ï¸ IMPORTANTE:**
- O primeiro build pode demorar alguns minutos (baixa dependÃªncias)
- Aguarde atÃ© ver a mensagem de sucesso abaixo
- **NÃ£o feche o terminal** - os containers precisam estar rodando

**Aguardar atÃ© ver:**
```
workhub_app  | INFO:     Uvicorn running on http://0.0.0.0:8000
workhub_app  | INFO:     Application startup complete.
workhub_app  | INFO:     Checking if database needs seeding...
workhub_app  | INFO:     Database not seeded. Running automatic seed...
workhub_app  | INFO:     âœ… Database automatically seeded on startup
```

**O que acontece automaticamente:**
- âœ… O sistema verifica se o banco jÃ¡ foi populado
- âœ… Se nÃ£o estiver populado, executa o seed automaticamente
- âœ… Cria 3 planos do WorkHub (Day Pass, Flex, Dedicado)
- âœ… Cria 25 usuÃ¡rios de teste
- âœ… Cria 25 conversas distribuÃ­das pelo funil
- âœ… Cria 15-20 leads qualificados
- âœ… Cria mensagens e objeÃ§Ãµes de exemplo

**Se houver erros:**
- Verifique se a porta 8000 nÃ£o estÃ¡ em uso
- Verifique se o Docker estÃ¡ rodando
- Verifique se o arquivo `.env` estÃ¡ configurado corretamente
- Verifique os logs: `docker-compose logs app`

**Nota:** O seed automÃ¡tico pode ser desabilitado definindo `AUTO_SEED=false` no `.env`. Nesse caso, vocÃª pode executar manualmente: `docker-compose exec app python -m app.core.seed`

### 4. Acesse o Sistema

- **API Documentation (Swagger)**: http://localhost:8000/docs
- **Interface Web (Frontend)**: http://localhost:8000/chat
- **ReDoc**: http://localhost:8000/redoc

### 5. Teste o Sistema (Opcional)

Execute o script de teste para verificar se tudo estÃ¡ funcionando:

```bash
docker-compose exec app python test_agent_flow.py
```

## ğŸ› ï¸ Comandos Ãšteis

### Parar os Containers

```bash
docker-compose down
```

### Ver Logs

```bash
# Todos os serviÃ§os
docker-compose logs -f

# Apenas a aplicaÃ§Ã£o
docker-compose logs -f app

# Apenas o banco
docker-compose logs -f db
```

### Reiniciar a AplicaÃ§Ã£o

```bash
docker-compose restart app
```

### Acessar Shell do Container

```bash
docker-compose exec app bash
```

### Recriar Dados de Teste

O seed Ã© executado automaticamente no startup. Para forÃ§ar recriaÃ§Ã£o:

```bash
# OpÃ§Ã£o 1: Desabilitar auto-seed e executar manualmente
# No .env: AUTO_SEED=false
docker-compose exec app python -m app.core.seed

# OpÃ§Ã£o 2: Limpar banco e reiniciar (seed automÃ¡tico executarÃ¡)
docker-compose down -v  # Remove volumes (apaga banco)
docker-compose up --build  # Recria tudo com seed automÃ¡tico
```

## ğŸ“¡ Principais Endpoints

### Chat

```bash
POST /api/v1/chat
{
  "message": "OlÃ¡, quero saber sobre coworking",
  "user_key": "user_123",
  "user_name": "JoÃ£o Silva"  # Opcional
}
```

### Analytics (Admin)

```bash
GET /api/v1/analytics/funnel?user_key=ADMIN_USER
GET /api/v1/analytics/plans-performance?user_key=ADMIN_USER
```

**Nota:** Endpoints de analytics requerem usuÃ¡rio admin (nome contendo "ADMIN").

## ğŸ¯ Agentes e Funcionalidades

### Sales Agent

- Conversa natural com clientes
- Recomenda planos baseado no perfil
- Coleta dados do lead (nome, email, telefone)
- Supera objeÃ§Ãµes comuns
- Cria leads automaticamente
- Solicita handoff quando apropriado

### Admin Agent

- Acessa mÃ©tricas do funil de vendas
- Analisa performance de planos
- Lista leads recentes
- Identifica objeÃ§Ãµes comuns
- Filtra conversas por estÃ¡gio
- Acesso restrito a usuÃ¡rios admin

### Analyst Agent

- Analisa conversas especÃ­ficas
- Calcula mÃ©tricas agregadas
- Identifica padrÃµes e tendÃªncias
- Gera insights acionÃ¡veis

## ğŸ“Š Dados de Teste e Analytics

Para informaÃ§Ãµes detalhadas sobre:
- Dados de teste gerados
- LÃ³gica das funÃ§Ãµes de analytics
- Como usar cada funÃ§Ã£o

Consulte: **[ANALYTICS.md](ANALYTICS.md)**

## ğŸ§ª Testes

O projeto possui uma suÃ­te completa de testes unitÃ¡rios e de integraÃ§Ã£o, cobrindo todas as funcionalidades principais sem dependÃªncia de LLM.

### Estrutura de Testes

```
tests/
â”œâ”€â”€ unit/                    # Testes unitÃ¡rios (sem LLM)
â”‚   â”œâ”€â”€ test_auth_service.py         # AutenticaÃ§Ã£o e autorizaÃ§Ã£o
â”‚   â”œâ”€â”€ test_prompt_service.py        # Carregamento de prompts
â”‚   â”œâ”€â”€ test_tools.py                 # Tools bÃ¡sicos (user, plan)
â”‚   â”œâ”€â”€ test_conversation_tools.py    # Tools de conversaÃ§Ã£o
â”‚   â”œâ”€â”€ test_lead_tools.py            # Tools de leads
â”‚   â”œâ”€â”€ test_message_tools.py         # Tools de mensagens
â”‚   â”œâ”€â”€ test_handoff_tools.py         # Tools de handoff
â”‚   â””â”€â”€ test_chat_service.py          # Service de chat (parcial)
â””â”€â”€ integration/             # Testes de integraÃ§Ã£o
    â”œâ”€â”€ test_chat_api.py              # Endpoints de chat
    â””â”€â”€ test_handoff.py               # Fluxo de handoff
```

### Executar Testes

```bash
# Todos os testes
docker-compose exec app pytest

# Apenas testes unitÃ¡rios
docker-compose exec app pytest tests/unit/

# Apenas testes de integraÃ§Ã£o
docker-compose exec app pytest tests/integration/

# Com cobertura de cÃ³digo
docker-compose exec app pytest --cov=app --cov-report=html

# Com output detalhado
docker-compose exec app pytest -v

# Teste especÃ­fico
docker-compose exec app pytest tests/unit/test_auth_service.py

# Teste rÃ¡pido do sistema (requer LLM configurado)
docker-compose exec app python test_agent_flow.py
```

### Cobertura de Testes

Os testes cobrem:
- âœ… **Services**: Auth, Prompt, Chat (parcial)
- âœ… **Tools**: User, Plan, Conversation, Lead, Message, Handoff
- âœ… **ValidaÃ§Ãµes**: UUIDs, entradas, roles, stages
- âœ… **Casos de erro**: Entradas invÃ¡lidas, recursos nÃ£o encontrados
- âœ… **IntegraÃ§Ã£o**: Endpoints da API, fluxos completos

**Total**: 75+ testes unitÃ¡rios e de integraÃ§Ã£o

### Nota sobre Testes com LLM

Os testes unitÃ¡rios foram projetados para **nÃ£o depender de LLM**, testando apenas a lÃ³gica de negÃ³cio, validaÃ§Ãµes e interaÃ§Ãµes com banco de dados. Isso garante:
- Testes rÃ¡pidos e confiÃ¡veis
- NÃ£o dependem de API keys externas
- Podem ser executados em CI/CD sem custos
- Focam na lÃ³gica do cÃ³digo, nÃ£o nas respostas do LLM

## ğŸ”§ Estrutura do Projeto

```
.
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/v1/          # Endpoints REST
â”‚   â”œâ”€â”€ agents/           # Agentes LangChain
â”‚   â”œâ”€â”€ tools/            # LangChain Tools
â”‚   â”œâ”€â”€ services/         # LÃ³gica de negÃ³cio
â”‚   â”œâ”€â”€ models/           # Modelos SQLAlchemy
â”‚   â””â”€â”€ core/             # ConfiguraÃ§Ãµes
â”œâ”€â”€ prompts/              # Templates de prompts
â”œâ”€â”€ frontend/             # Interface web
â”œâ”€â”€ tests/                # Testes
â””â”€â”€ alembic/              # Migrations
```

## ğŸ¨ Diferenciais

âœ… **Multi-Agente** - Sales, Analyst e Admin agents  
âœ… **Function Calling** - InteraÃ§Ã£o estruturada com DB  
âœ… **Clean Architecture** - SeparaÃ§Ã£o de responsabilidades  
âœ… **Async/Await** - Performance otimizada  
âœ… **Dockerizado** - Setup simples  
âœ… **Frontend Integrado** - Interface web para testes  
âœ… **Analytics Completo** - MÃ©tricas e insights detalhados  

## ğŸ“š DocumentaÃ§Ã£o Adicional

- **[ANALYTICS.md](ANALYTICS.md)** - Dados de teste e funÃ§Ãµes de analytics
- **[TROUBLESHOOTING.md](TROUBLESHOOTING.md)** - SoluÃ§Ã£o de problemas comuns

## ğŸ”’ SeguranÃ§a

**âš ï¸ IMPORTANTE para ProduÃ§Ã£o:**

- Altere todas as senhas padrÃ£o (banco de dados, etc.)
- Use variÃ¡veis de ambiente seguras
- Nunca commite arquivos `.env` com chaves reais
- Configure HTTPS em produÃ§Ã£o
- Use secrets management adequado (AWS Secrets Manager, HashiCorp Vault, etc.)
- Revise as permissÃµes de acesso ao banco de dados

## ğŸ¤ Contribuindo

Este Ã© um projeto de demonstraÃ§Ã£o tÃ©cnica. SugestÃµes e melhorias sÃ£o bem-vindas!

## ğŸ“ LicenÃ§a

Este projeto foi desenvolvido como teste tÃ©cnico e Ã© de uso livre para fins educacionais.

---

**Tecnologias**: Python, FastAPI, LangChain, **OpenAI** (principal), PostgreSQL, Docker, SQLAlchemy, Pydantic, Pytest

---

## ğŸ“ Nota sobre o Provider LLM

Este projeto foi desenvolvido para usar **OpenAI** como provider principal de IA, conforme solicitado. O sistema suporta Google Gemini como alternativa, mas a configuraÃ§Ã£o padrÃ£o e recomendada Ã© OpenAI.

Para usar OpenAI, configure no `.env`:
```env
OPENAI_API_KEY=sk-your-key-here
LLM_PROVIDER=openai
OPENAI_MODEL=gpt-4o-mini  # ou gpt-4o, gpt-3.5-turbo
```
